{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "347d2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6d543c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7f7fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1366bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "from PIL import Image\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, m_dir, transform):\n",
    "        \n",
    "        # Set the loading directory\n",
    "        self.m_dir = m_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        downs_imgs = os.listdir(os.path.join(m_dir, 'downs'))\n",
    "        peaks_imgs = os.listdir(os.path.join(m_dir, 'peaks'))\n",
    "        rises_imgs = os.listdir(os.path.join(m_dir, 'rises'))\n",
    "        \n",
    "        dimg = natsorted(downs_imgs)\n",
    "        pimg = natsorted(peaks_imgs)\n",
    "        rimg = natsorted(rises_imgs)\n",
    "        self.total_imgs = dimg + pimg + rimg\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        # Return the previously computed number of images\n",
    "        return len(self.total_imgs)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "     \n",
    "        # Use PIL for image loading\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        # Apply the transformations\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d388713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_dict = {\n",
    "        'src': transforms.Compose(\n",
    "        [transforms.RandomResizedCrop(224),\n",
    "         transforms.RandomHorizontalFlip(),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225]),\n",
    "         ]),\n",
    "        'tar': transforms.Compose(\n",
    "        [transforms.Resize(224),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225]),\n",
    "         ])\n",
    "}\n",
    "\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e5d9ac4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-3df3f62d8228>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, \n\u001b[0;32m      3\u001b[0m                                           drop_last=False, num_workers=4)\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# prints shape of image with single batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = TrainDataset(m_dir=\".\\\\dataset\\\\Train\", transform=transform_dict)\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True, \n",
    "                                          drop_last=False, num_workers=4)\n",
    "print(next(iter(data_loader)).shape)  # prints shape of image with single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fc8317c",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 6-7: malformed \\N character escape (<ipython-input-12-90d9aacb3549>, line 16)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-12-90d9aacb3549>\"\u001b[1;36m, line \u001b[1;32m16\u001b[0m\n\u001b[1;33m    data = datasets.ImageFolder(root= \"D:\\git\\Neural-diagnostics_turnmachines\" + dir, transform=transform_dict[phase])\u001b[0m\n\u001b[1;37m                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 6-7: malformed \\N character escape\n"
     ]
    }
   ],
   "source": [
    "transform_dict = {\n",
    "        'src': transforms.Compose(\n",
    "        [transforms.RandomResizedCrop(224),\n",
    "         transforms.RandomHorizontalFlip(),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225]),\n",
    "         ]),\n",
    "        'tar': transforms.Compose(\n",
    "        [transforms.Resize(224),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225]),\n",
    "         ])\n",
    "}\n",
    "data = datasets.ImageFolder(root= \"D:\\git\\Neural-diagnostics_turnmachines\" + dir, transform=transform_dict[phase])\n",
    "data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=True, \n",
    "                                          drop_last=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc10347",
   "metadata": {},
   "source": [
    "\n",
    "    '''\n",
    "    trainset_folder = 'dataset/Train'\n",
    "        \n",
    "    for downs in os.listdir(trainset_folder):\n",
    "        down_folder = os.path.join(trainset_folder, 'downs')\n",
    "        with open(down_folder, 'r') as downs_file:\n",
    "            for name in downs_file.read().splitlines():\n",
    "                self.samples.append((type))\n",
    "            \n",
    "    for peaks in os.listdir(trainset_folder):\n",
    "        peaks_folder = os.path.join(trainset_folder, 'peaks')\n",
    "        with open(peaks_folder, 'r') as peaks_file:\n",
    "            for name in peaks_file.read().splitlines():\n",
    "                self.samples.append((type))\n",
    "            \n",
    "    for rises in os.listdir(trainset_folder):\n",
    "        rises_folder = os.path.join(trainset_folder, 'rises')\n",
    "        with open(rises_folder, 'r') as rises_file:\n",
    "            for name in rises_file.read().splitlines():\n",
    "                self.samples.append((type))\n",
    "            \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset = TrainDataset('dataset/Train')\n",
    "    print(len(dataset))\n",
    "    print(dataset[420])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
