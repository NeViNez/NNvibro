{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13dd15b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "453f6a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")  # здесь вы можете продолжить, например,cuda:1 cuda:2... и т. д. \n",
    "    print(\"Running on the GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Running on the CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08182a1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-a406269d10d3>, line 38)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-a406269d10d3>\"\u001b[1;36m, line \u001b[1;32m38\u001b[0m\n\u001b[1;33m    print(,len(training_data))\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "REBUILD_DATA = False # set to true to one once, then back to false unless you want to change something in your training data.\n",
    "class DogsVSCats():\n",
    "    IMG_SIZE = 50\n",
    "    CATS = \"PetImages/Cat\"\n",
    "    DOGS = \"PetImages/Dog\"\n",
    "    TESTING = \"PetImages/Testing\"\n",
    "    LABELS = {CATS: 0, DOGS: 1}\n",
    "    training_data = []\n",
    "    catcount = 0\n",
    "    dogcount = 0\n",
    "    def make_training_data(self):\n",
    "        for label in self.LABELS:\n",
    "            print(label)\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                if \"jpg\" in f:\n",
    "                    try:\n",
    "                        path = os.path.join(label, f)\n",
    "                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
    "                        self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot \n",
    "                        #print(np.eye(2)[self.LABELS[label]])\n",
    "                        if label == self.CATS:\n",
    "                            self.catcount += 1\n",
    "                        elif label == self.DOGS:\n",
    "                            self.dogcount += 1\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                        #print(label, f, str(e))\n",
    "        np.random.shuffle(self.training_data)\n",
    "        np.save(\"training_data.npy\", self.training_data)\n",
    "        print('Cats:',dogsvcats.catcount)\n",
    "        print('Dogs:',dogsvcats.dogcount)\n",
    "        \n",
    "if REBUILD_DATA:\n",
    "    dogsvcats = DogsVSCats()\n",
    "    dogsvcats.make_training_data()\n",
    "training_data = np.load(\"training_data.npy\", allow_pickle=True)\n",
    "print(len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97298e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # just run the init of parent class (nn.Module)\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5) # input is 1 image, 32 output channels, 5x5 kernel / window\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5) # input is 32, bc the first layer output 32. Then we say the output will be 64 channels, 5x5 kernel / window\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "        x = torch.randn(50,50).view(-1,1,50,50)\n",
    "        self._to_linear = None\n",
    "        self.convs(x)\n",
    "        self.fc1 = nn.Linear(self._to_linear, 512) #flattening.\n",
    "        self.fc2 = nn.Linear(512, 2) # 512 in, 2 out bc we're doing 2 classes (dog vs cat).\n",
    "    def convs(self, x):\n",
    "        # max pooling over 2x2\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv3(x)), (2, 2))\n",
    "        if self._to_linear is None:\n",
    "            self._to_linear = x[0].shape[0]*x[0].shape[1]*x[0].shape[2]\n",
    "        return x\n",
    "    def forward(self, x):\n",
    "        x = self.convs(x)\n",
    "        x = x.view(-1, self._to_linear)  # .view is reshape ... this flattens X before \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x) # bc this is our output layer. No activation here.\n",
    "        return F.softmax(x, dim=1)\n",
    "net = Net().to(device)\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09fdcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)\n",
    "loss_function = nn.MSELoss()\n",
    "X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)\n",
    "X = X/255.0\n",
    "y = torch.Tensor([i[1] for i in training_data])\n",
    "VAL_PCT = 0.1  # lets reserve 10% of our data for validation\n",
    "val_size = int(len(X)*VAL_PCT)\n",
    "print(val_size)\n",
    "\n",
    "train_X = X[:-val_size].to(device)\n",
    "train_y = y[:-val_size].to(device)\n",
    "test_X = X[-val_size:].to(device)\n",
    "test_y = y[-val_size:].to(device)\n",
    "\n",
    "print(len(train_X), len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10287a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_pass(X, y, train=False):\n",
    "    if train:\n",
    "        net.zero_grad()\n",
    "    outputs = net(X)\n",
    "    matches  = [torch.argmax(i)==torch.argmax(j) for i, j in zip(outputs, y)]\n",
    "    acc = matches.count(True)/len(matches)\n",
    "    loss = loss_function(outputs, y)\n",
    "    if train:\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return acc, loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0209b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(size=32):\n",
    "    X, y = test_X[:size], test_y[:size]\n",
    "    val_acc, val_loss = fwd_pass(X.view(-1, 1, 50, 50).to(device), y.to(device))\n",
    "    return val_acc, val_loss\n",
    "val_acc, val_loss = test(size=100)\n",
    "print(val_acc, val_loss) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "2eed095a",
   "metadata": {},
   "source": [
    "MODEL_NAME = f\"model-{int(time.time())}\"  # gives a dynamic model name, to just help with things getting messy over time. \n",
    "net = Net().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "print(MODEL_NAME)\n",
    "def train(net):\n",
    "    BATCH_SIZE = 1000\n",
    "    EPOCHS = 30\n",
    "    with open(\"model.log\", \"a\") as f:\n",
    "        for epoch in range(EPOCHS):\n",
    "            for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
    "                batch_X = train_X[i:i+BATCH_SIZE].view(-1,1,50,50)\n",
    "                batch_y = train_y[i:i+BATCH_SIZE]\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                acc, loss = fwd_pass(batch_X, batch_y, train=True)\n",
    "                #print(f\"Acc: {round(float(acc),2)}  Loss: {round(float(loss),4)}\")\n",
    "                #f.write(f\"{MODEL_NAME},{round(time.time(),3)},train,{round(float(acc),2)},{round(float(loss),4)}\\n\")\n",
    "                # just to show the above working, and then get out:\n",
    "                if i % 50 == 0:\n",
    "                    val_acc, val_loss = test(size=100)\n",
    "                    f.write(f\"{MODEL_NAME},{round(time.time(),3)},{round(float(acc),2)},{round(float(loss), 4)},{round(float(val_acc),2)},{round(float(val_loss),4)},{epoch}\\n\")\n",
    "train(net) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3cc160",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = f\"model-{int(time.time())}\"  # gives a dynamic model name, to just help with things getting messy over time. \n",
    "net = Net().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "def train(net):\n",
    "    BATCH_SIZE = 64\n",
    "    EPOCHS = 10\n",
    "    with open(\"model.log\", \"a\") as f:\n",
    "        for epoch in range(EPOCHS):\n",
    "            for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
    "                batch_X = train_X[i:i+BATCH_SIZE].view(-1,1,50,50)\n",
    "                batch_y = train_y[i:i+BATCH_SIZE]\n",
    "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "                acc, loss = fwd_pass(batch_X, batch_y, train=True)\n",
    "                #print(f\"Acc: {round(float(acc),2)}  Loss: {round(float(loss),4)}\")\n",
    "                #f.write(f\"{MODEL_NAME},{round(time.time(),3)},train,{round(float(acc),2)},{round(float(loss),4)}\\n\")\n",
    "                # just to show the above working, and then get out:\n",
    "                if i % 10 == 0:\n",
    "                    val_acc, val_loss = test(size=100)\n",
    "                    f.write(f\"{MODEL_NAME},{round(time.time(),3)},{round(float(acc),2)},{round(float(loss), 4)},{round(float(val_acc),2)},{round(float(val_loss),4)}\\n\")\n",
    "train(net) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df82deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(size=32):\n",
    "    X, y = test_X[:size], test_y[:size]\n",
    "    val_acc, val_loss = fwd_pass(X.view(-1, 1, 50, 50).to(device), y.to(device))\n",
    "    return val_acc, val_loss\n",
    "val_acc, val_loss = test(size=100)\n",
    "print(val_acc, val_loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e67130",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X[301].view(50,50))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dbce19",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_featureset = X[301]\n",
    "reshaped_for_network = a_featureset.view(-1, 1, 50, 50).to(device) # 784 = 28*28 наше разрешение.\n",
    "output = net(reshaped_for_network) #результат будет списком предсказаний нашей сети.\n",
    "first_pred = output[0]\n",
    "print(first_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cfd1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use(\"ggplot\")\n",
    "model_name = MODEL_NAME #\"model-1570499409\" # grab whichever model name you want here. We could also just reference the MODEL_NAME if you're in a notebook still.\n",
    "def create_acc_loss_graph(model_name):\n",
    "    contents = open(\"model.log\", \"r\").read().split(\"\\n\")\n",
    "    times = []\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    val_accs = []\n",
    "    val_losses = []\n",
    "    for c in contents:\n",
    "        if model_name in c:\n",
    "            name, timestamp, acc, loss, val_acc, val_loss = c.split(\",\")\n",
    "            times.append(float(timestamp))\n",
    "            accuracies.append(float(acc))\n",
    "            losses.append(float(loss))\n",
    "            val_accs.append(float(val_acc))\n",
    "            val_losses.append(float(val_loss))\n",
    "    fig = plt.figure()\n",
    "    ax1 = plt.subplot2grid((2,1), (0,0))\n",
    "    ax2 = plt.subplot2grid((2,1), (1,0), sharex=ax1)\n",
    "    ax1.plot(times, accuracies, label=\"acc\")\n",
    "    ax1.plot(times, val_accs, label=\"val_acc\")\n",
    "    ax1.legend(loc=2)\n",
    "    ax2.plot(times,losses, label=\"loss\")\n",
    "    ax2.plot(times,val_losses, label=\"val_loss\")\n",
    "    ax2.legend(loc=2)\n",
    "    plt.show()\n",
    "create_acc_loss_graph(model_name) "
   ]
  },
  {
   "cell_type": "raw",
   "id": "10290154",
   "metadata": {},
   "source": [
    "style.use(\"ggplot\")\n",
    "model_name = \"model-1570499915\" # grab whichever model name you want here. We could also just reference the MODEL_NAME if you're in a notebook still.\n",
    "def create_acc_loss_graph(model_name):\n",
    "    contents = open(\"model.log\", \"r\").read().split(\"\\n\")\n",
    "    times = []\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    val_accs = []\n",
    "    val_losses = []\n",
    "    for c in contents:\n",
    "        if model_name in c:\n",
    "            name, timestamp, acc, loss, val_acc, val_loss, epoch = c.split(\",\")\n",
    "            times.append(float(timestamp))\n",
    "            accuracies.append(float(acc))\n",
    "            losses.append(float(loss))\n",
    "            val_accs.append(float(val_acc))\n",
    "            val_losses.append(float(val_loss))\n",
    "    fig = plt.figure()\n",
    "    ax1 = plt.subplot2grid((2,1), (0,0))\n",
    "    ax2 = plt.subplot2grid((2,1), (1,0), sharex=ax1)\n",
    "    ax1.plot(times, accuracies, label=\"acc\")\n",
    "    ax1.plot(times, val_accs, label=\"val_acc\")\n",
    "    ax1.legend(loc=2)\n",
    "    ax2.plot(times,losses, label=\"loss\")\n",
    "    ax2.plot(times,val_losses, label=\"val_loss\")\n",
    "    ax2.legend(loc=2)\n",
    "    plt.show()\n",
    "create_acc_loss_graph(model_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c5fe62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
