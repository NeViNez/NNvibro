{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "347d2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "import ignite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6d543c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7f7fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1366bca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from natsort import natsorted\n",
    "from PIL import Image\n",
    "\n",
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, m_dir, transform):\n",
    "        \n",
    "        # Set the loading directory\n",
    "        self.m_dir = m_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        downs_imgs = os.listdir(os.path.join(m_dir, 'downs'))\n",
    "        peaks_imgs = os.listdir(os.path.join(m_dir, 'peaks'))\n",
    "        rises_imgs = os.listdir(os.path.join(m_dir, 'rises'))\n",
    "        \n",
    "        dimg = natsorted(downs_imgs)\n",
    "        pimg = natsorted(peaks_imgs)\n",
    "        rimg = natsorted(rises_imgs)\n",
    "        self.total_imgs = dimg + pimg + rimg\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        # Return the previously computed number of images\n",
    "        return len(self.total_imgs)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_loc = os.path.join(self.main_dir, self.total_imgs[idx])\n",
    "     \n",
    "        # Use PIL for image loading\n",
    "        image = Image.open(img_loc).convert(\"RGB\")\n",
    "        # Apply the transformations\n",
    "        tensor_image = self.transform(image)\n",
    "        return tensor_image\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e5d9ac4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-4a77dc4a562d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\".\\\\dataset\\\\Train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# prints shape of image with single batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transform' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = TrainDataset(m_dir=\".\\\\dataset\\\\Train\", transform=transform)\n",
    "dataloader = DataLoader(dataset)\n",
    "print(next(iter(dataloader)).shape)  # prints shape of image with single batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc10347",
   "metadata": {},
   "source": [
    "\n",
    "    '''\n",
    "    trainset_folder = 'dataset/Train'\n",
    "        \n",
    "    for downs in os.listdir(trainset_folder):\n",
    "        down_folder = os.path.join(trainset_folder, 'downs')\n",
    "        with open(down_folder, 'r') as downs_file:\n",
    "            for name in downs_file.read().splitlines():\n",
    "                self.samples.append((type))\n",
    "            \n",
    "    for peaks in os.listdir(trainset_folder):\n",
    "        peaks_folder = os.path.join(trainset_folder, 'peaks')\n",
    "        with open(peaks_folder, 'r') as peaks_file:\n",
    "            for name in peaks_file.read().splitlines():\n",
    "                self.samples.append((type))\n",
    "            \n",
    "    for rises in os.listdir(trainset_folder):\n",
    "        rises_folder = os.path.join(trainset_folder, 'rises')\n",
    "        with open(rises_folder, 'r') as rises_file:\n",
    "            for name in rises_file.read().splitlines():\n",
    "                self.samples.append((type))\n",
    "            \n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataset = TrainDataset('dataset/Train')\n",
    "    print(len(dataset))\n",
    "    print(dataset[420])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
